{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# alt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import make_moons, make_circles, make_classification\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC, LinearSVC, NuSVC\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import VotingClassifier, RandomForestClassifier, AdaBoostClassifier, ExtraTreesClassifier, BaggingClassifier, GradientBoostingClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.preprocessing import StandardScaler  \n",
    "\n",
    "types = {k: np.int32 for k in range(28)}\n",
    "types[1] = np.string_\n",
    "types[2] = np.string_\n",
    "\n",
    "fifa = pd.read_csv(\"data/data_simple_test.csv\", encoding='utf8', dtype=types, index_col=0, header=None)\n",
    "# fifa = fifa.drop([1, 2], axis=1)\n",
    "fifa.columns = range(0, len(fifa.columns))\n",
    "\n",
    "#fifa.head()\n",
    "\n",
    "feature = fifa.drop([24], axis=1).values\n",
    "target = fifa[24].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(feature, target, test_size=0.2)\n",
    "print(len(X_train))\n",
    "print(len(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = [\n",
    "    LinearSVC(penalty='l2', loss='squared_hinge', dual=True, tol=0.0001,\n",
    "              C=1.0, multi_class='ovr', fit_intercept=True, intercept_scaling=1,\n",
    "              class_weight=None, verbose=0, random_state=None, max_iter=1000),\n",
    "    #langsam LinearSVC(penalty='l2', loss='squared_hinge', dual=True, tol=0.0001,\n",
    "    #          C=1.0, multi_class='crammer_singer', fit_intercept=True, intercept_scaling=1,\n",
    "    #          class_weight=None, verbose=0, random_state=None, max_iter=1000),\n",
    "    LinearSVC(penalty='l2', loss='squared_hinge', dual=True, tol=0.0001,\n",
    "              C=7.0, multi_class='ovr', fit_intercept=True, intercept_scaling=1,\n",
    "              class_weight=None, verbose=0, random_state=None, max_iter=1000),\n",
    "    LinearSVC(penalty='l2', loss='squared_hinge', dual=False, tol=0.0001,\n",
    "              C=1.0, multi_class='ovr', fit_intercept=True, intercept_scaling=1,\n",
    "              class_weight=None, verbose=0, random_state=None, max_iter=1000),\n",
    "    LinearSVC(penalty='l2', loss='squared_hinge', dual=True, tol=0.1,\n",
    "              C=1.0, multi_class='ovr', fit_intercept=True, intercept_scaling=1,\n",
    "              class_weight=None, verbose=0, random_state=None, max_iter=1000),\n",
    "]\n",
    "result = []\n",
    "result2 = []\n",
    "for i, clf in enumerate(classifiers):\n",
    "        \n",
    "    c = clf.fit(X_train, y_train)\n",
    "\n",
    "    l = []\n",
    "    for i, p in enumerate(clf.predict(X_test)):\n",
    "        l.append(y_test[i] == p)\n",
    "        #print(p)\n",
    "        #print(y_test[i])\n",
    "    print(\"check\")\n",
    "\n",
    "    score = clf.score(X_test, y_test)\n",
    "    scores = cross_val_score(clf, X_train, y_train)\n",
    "    \n",
    "    result.append('%s -> %f' % (type(c).__name__, score))\n",
    "    result2.append('%s -> %f' % (type(c).__name__, scores.mean()))\n",
    "\n",
    "print(result)\n",
    "print(result2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fifa.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adaBoostClassifiers = [\n",
    "    AdaBoostClassifier(DecisionTreeClassifier(max_depth=1),\n",
    "                         algorithm=\"SAMME\",n_estimators=200),\n",
    "    #AdaBoostClassifier(MLPClassifier(alpha=0),\n",
    "    #                     algorithm=\"SAMME\",n_estimators=200),\n",
    "    AdaBoostClassifier(),\n",
    "    AdaBoostRegressor(),\n",
    "    AdaBoostClassifier(DecisionTreeClassifier(max_depth=1),\n",
    "                         algorithm=\"SAMME.R\",n_estimators=200),\n",
    "    AdaBoostClassifier(DecisionTreeClassifier(max_depth=1),\n",
    "                         algorithm=\"SAMME\",n_estimators=1),\n",
    "    AdaBoostClassifier(DecisionTreeClassifier(max_depth=1),\n",
    "                         algorithm=\"SAMME\",n_estimators=50),\n",
    "    AdaBoostClassifier(DecisionTreeClassifier(max_depth=1),\n",
    "                         algorithm=\"SAMME\",n_estimators=100),\n",
    "    AdaBoostClassifier(DecisionTreeClassifier(max_depth=1),\n",
    "                         algorithm=\"SAMME\",n_estimators=500)\n",
    "]\n",
    "    \n",
    "result = []\n",
    "for i, clf in enumerate(adaBoostClassifiers):\n",
    "       \n",
    "    c = clf.fit(X_train, y_train)\n",
    "\n",
    "    l = []\n",
    "    for i, p in enumerate(clf.predict(X_test)):\n",
    "        l.append(y_test[i] == p)\n",
    "\n",
    "    score = clf.score(X_test, y_test)\n",
    "    result.append('%s -> %f' % (type(c).__name__, score))\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "clf1 = AdaBoostClassifier()\n",
    "clf2 = RandomForestClassifier(random_state=1)\n",
    "clf3 = GaussianNB()\n",
    "clf4 = LinearSVC()\n",
    "clf5 = SVC()\n",
    "clf6 = KNeighborsClassifier()\n",
    "clf7 = RandomForestClassifier()\n",
    "clf8 = ExtraTreesClassifier()\n",
    "clf9 = BaggingClassifier()\n",
    "clf10 = GradientBoostingClassifier()\n",
    "\n",
    "eclf = VotingClassifier(estimators=[('abc', clf1), ('rf', clf2), ('gnb', clf3), ('lsvc', clf4), ('svc', clf5), ('knc', clf6), ('rfc', clf7), ('etc', clf8), ('bc', clf9), ('gbc', clf10),], voting='hard')\n",
    "\n",
    "for clf, label in zip([clf1, clf2, clf3, clf4, clf5, clf6, clf7, clf8, clf9, clf10, eclf], ['AdaBoost', 'Random Forest', 'naive Bayes', 'Ensemble', 'LinearSVC', 'SVC', 'KNeighborsClassifier', 'RandomForestClassifier', 'ExtraTreesClassifier', 'BaggingClassifier', 'GradientBoostingClassifier']):\n",
    "    scores = cross_val_score(clf, X_train, y_train, cv=5, scoring='accuracy')\n",
    "    print(\"Accuracy: %0.2f (+/- %0.2f) [%s]\" % (scores.mean(), scores.std(), label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test der Classifier mit neuem Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC, LinearSVC, NuSVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomTreesEmbedding, VotingClassifier, RandomForestClassifier, AdaBoostClassifier, ExtraTreesClassifier, BaggingClassifier, GradientBoostingClassifier\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "types = {k: np.int32 for k in range(21515)}\n",
    "\n",
    "fifa = pd.read_csv(\"data/data_complex_train.csv\", encoding='utf8', dtype=types, index_col=None, header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>21506</th>\n",
       "      <th>21507</th>\n",
       "      <th>21508</th>\n",
       "      <th>21509</th>\n",
       "      <th>21510</th>\n",
       "      <th>21511</th>\n",
       "      <th>21512</th>\n",
       "      <th>21513</th>\n",
       "      <th>21514</th>\n",
       "      <th>21515</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1465509600</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1465596000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1465941600</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1465941600</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1466287200</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21516 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0      1      2      3      4      5      6      7      8      9      \\\n",
       "0  1465509600      0      0      0      0      0      0      0      0      0   \n",
       "1  1465596000      0      0      0      0      0      0      0      0      0   \n",
       "2  1465941600      0      0      0      0      0      0      0      0      0   \n",
       "3  1465941600      0      0      0      0      0      0      0      0      0   \n",
       "4  1466287200      0      0      0      0      0      0      0      0      0   \n",
       "\n",
       "   ...    21506  21507  21508  21509  21510  21511  21512  21513  21514  21515  \n",
       "0  ...        0      0      0      0      0      0      0      0      0      1  \n",
       "1  ...        0      0      0      0      0      0      0      0      0      2  \n",
       "2  ...        0      0      0      0      0      0      0      0      0      1  \n",
       "3  ...        0      0      0      0      0      0      0      0      0      0  \n",
       "4  ...        0      0      0      0      0      0      0      0      0      0  \n",
       "\n",
       "[5 rows x 21516 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fifa.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sparse Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature = fifa.drop([21515], axis=1).values\n",
    "feature2 = fifa2.drop([21515], axis=1).values\n",
    "target = fifa[21515].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_csc = sp.sparse.csc_matrix(feature)\n",
    "feature_csr = sp.sparse.csr_matrix(feature)\n",
    "feature_csc2 = sp.sparse.csc_matrix(feature2)\n",
    "feature_csr2 = sp.sparse.csr_matrix(feature2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5170\n",
      "1293\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(feature_csc, target, test_size=0.2)\n",
    "print(X_train.shape[0])\n",
    "print(X_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = [\n",
    "    LinearSVC(),\n",
    "    SVC(),\n",
    "    KNeighborsClassifier(),\n",
    "    AdaBoostClassifier(),\n",
    "    RandomForestClassifier(),\n",
    "    AdaBoostClassifier(),\n",
    "    ExtraTreesClassifier(),\n",
    "    BaggingClassifier(),\n",
    "    GradientBoostingClassifier()\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.50 (+/- 0.02) [Esemble soft]\n"
     ]
    }
   ],
   "source": [
    "clf1 = AdaBoostClassifier()\n",
    "clf2 = RandomForestClassifier()\n",
    "clf3 = BaggingClassifier()\n",
    "clf4 = GradientBoostingClassifier()\n",
    "\n",
    "# eclf = VotingClassifier(estimators=[('ab', clf1), ('rf', clf2), ('b', clf3), ('gb', clf4)], voting='hard')\n",
    "eclf1 = VotingClassifier(estimators=[('ab', clf1), ('rf', clf2), ('b', clf3), ('gb', clf4)], voting='soft')\n",
    "# eclf2 = VotingClassifier(estimators=[('ab', clf1), ('rf', clf2), ('b', clf3), ('gb', clf4)], voting='soft', weights=[5,2,2,10])\n",
    "\n",
    "scores = cross_val_score(eclf1, X_train, y_train, cv=5, scoring='accuracy')\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f) [%s]\" % (scores.mean(), scores.std(), 'Esemble soft'))\n",
    "\n",
    "# for clf, label in zip([clf1, clf2, clf3, clf4, eclf, eclf1, eclf2], ['AdaBoost', 'Random Forest', 'Bagging', 'GradientBoosting', 'Ensemble hard', 'Esemble soft', 'Ensemble soft weights']):\n",
    "#     scores = cross_val_score(clf, X_train, y_train, cv=5, scoring='accuracy')\n",
    "#     print(\"Accuracy: %0.2f (+/- %0.2f) [%s]\" % (scores.mean(), scores.std(), label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['LinearSVC -> 0.448569', 'SVC -> 0.405259', 'KNeighborsClassifier -> 0.358082', 'AdaBoostClassifier -> 0.466357', 'RandomForestClassifier -> 0.481052', 'AdaBoostClassifier -> 0.466357', 'ExtraTreesClassifier -> 0.488786', 'BaggingClassifier -> 0.462490', 'GradientBoostingClassifier -> 0.477958']\n"
     ]
    }
   ],
   "source": [
    "result = []\n",
    "for i, clf in enumerate(classifiers):\n",
    "        \n",
    "    c = clf.fit(X_train, y_train)\n",
    "    score = clf.score(X_test, y_test)\n",
    "    \n",
    "    result.append('%s -> %f' % (type(c).__name__, score))\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiersPenalty = [\n",
    "    LinearSVC(penalty='l1', dual=False), # besser\n",
    "    LinearSVC(penalty='l2'), #immer gleich (45,0889%) und schlechter\n",
    "    \n",
    "]\n",
    "\n",
    "classifiersDual = [\n",
    "    LinearSVC(dual=False),\n",
    "    LinearSVC(dual=True) # egal beides immer 45,0889%\n",
    "]\n",
    "\n",
    "classifiersLoss = [\n",
    "    LinearSVC(loss='hinge'), #immer 43,5422%\n",
    "    LinearSVC(loss='squared_hinge') #immer 45,0889%\n",
    "]\n",
    "\n",
    "classifiersTol = [\n",
    "    LinearSVC(tol=100),# instabil (min 43%) aber deutlich bessere Werte bis zu 53%\n",
    "    LinearSVC(tol=10),# instabil aber deutlich bessere Werte bis zu 53%\n",
    "    LinearSVC(tol=5),\n",
    "    LinearSVC(tol=1),# stabil um die 46%\n",
    "    LinearSVC(tol=0.1),# stabil um die 46%\n",
    "    LinearSVC(tol=0.0001),# stabil um die 46%\n",
    "    LinearSVC(tol=0.0000001),# stabil um die 46%\n",
    "    #LinearSVC(tol=0) fehler\n",
    "]\n",
    "\n",
    "classifiersC = [\n",
    "    #LinearSVC(C=10),\n",
    "    #LinearSVC(C=5),\n",
    "    #LinearSVC(C=4.5),\n",
    "    #LinearSVC(C=4.25),\n",
    "    #LinearSVC(C=4.1),\n",
    "    #LinearSVC(C=4),# steigt von beiden Seiten bis hier\n",
    "    #LinearSVC(C=3.9),\n",
    "    LinearSVC(C=3.8),\n",
    "    LinearSVC(C=3.75),\n",
    "    LinearSVC(C=3.7),\n",
    "    LinearSVC(C=3.65),\n",
    "    LinearSVC(C=3.6),\n",
    "    LinearSVC(C=3.55),#46.9451% nichts besseres drum herum\n",
    "    LinearSVC(C=3.5),\n",
    "    LinearSVC(C=3.4),\n",
    "    #LinearSVC(C=3),\n",
    "    #LinearSVC(C=2),\n",
    "    #LinearSVC(C=1),\n",
    "    #LinearSVC(C=0), fehler\n",
    "    #LinearSVC(C=-5), fehler\n",
    "    #LinearSVC(C=-10) fehler\n",
    "]\n",
    "\n",
    "classifiersMultiClass = [\n",
    "    LinearSVC(multi_class='ovr'),#46,4%\n",
    "    LinearSVC(multi_class='crammer_singer')#45,9%\n",
    "]\n",
    "\n",
    "classifiersFitIntercept = [\n",
    "    LinearSVC(fit_intercept=True),#46,40%\n",
    "    LinearSVC(fit_intercept=False)#46,48%\n",
    "]\n",
    "\n",
    "classifiersVerbose = [\n",
    "    LinearSVC(verbose=0),\n",
    "    LinearSVC(verbose=1),# gar kein unterschied nur Output\n",
    "    LinearSVC(verbose=-1)\n",
    "]\n",
    "\n",
    "classifiersInterceptScaling = [\n",
    "    #LinearSVC(intercept_scaling=-2), fehler\n",
    "    #LinearSVC(intercept_scaling=-1), fehler\n",
    "    #LinearSVC(intercept_scaling=0), fehler\n",
    "    LinearSVC(intercept_scaling=1),#46,40\n",
    "    LinearSVC(intercept_scaling=2),#höher 46,48\n",
    "    LinearSVC(intercept_scaling=3),\n",
    "    LinearSVC(intercept_scaling=4)\n",
    "]\n",
    "\n",
    "classifiersClassWeight = [\n",
    "    LinearSVC(class_weight='balanced'),#46,7%\n",
    "    LinearSVC(class_weight=None),#46,4%\n",
    "]\n",
    "\n",
    "classifiersRandomState = [\n",
    "    LinearSVC(random_state=None),#keine Auswirkungen\n",
    "    LinearSVC(random_state=0),\n",
    "    LinearSVC(random_state=1),\n",
    "    LinearSVC(random_state=10),\n",
    "    LinearSVC(random_state=100),\n",
    "    LinearSVC(random_state=1000),\n",
    "]\n",
    "\n",
    "classifiersMaxIter = [\n",
    "    LinearSVC(max_iter=10),#instabiler aber prinzipiell besser\n",
    "    LinearSVC(max_iter=1),#instabil aber tendez über 50%\n",
    "    LinearSVC(max_iter=50),\n",
    "    LinearSVC(max_iter=90),\n",
    "    LinearSVC(max_iter=100),#ab hier immer 46,4%\n",
    "    LinearSVC(max_iter=1000),\n",
    "    LinearSVC(max_iter=10000),\n",
    "    LinearSVC(max_iter=100000),\n",
    "    LinearSVC(max_iter=1000000),\n",
    "]\n",
    "\n",
    "classifiersOpt = [\n",
    "    LinearSVC(penalty='l1', dual=False, loss='squared_hinge', tol=10, multi_class='ovr', C=3.55,\n",
    "              fit_intercept=False, intercept_scaling=2, class_weight='balanced', max_iter=1),\n",
    "    LinearSVC(penalty='l1', dual=False, loss='squared_hinge', tol=100, multi_class='ovr', C=3.55, \n",
    "              fit_intercept=False, intercept_scaling=2, class_weight='balanced', max_iter=1),\n",
    "    LinearSVC(penalty='l2', dual=True, loss='squared_hinge', tol=10, multi_class='ovr', C=3.55, \n",
    "              fit_intercept=False, intercept_scaling=2, class_weight='balanced', max_iter=1),\n",
    "    LinearSVC(penalty='l2', dual=True, loss='squared_hinge', tol=100, multi_class='ovr', C=3.55,\n",
    "              fit_intercept=False, intercept_scaling=2, class_weight='balanced', max_iter=1)\n",
    "]#Schwankungen eventuell noch mit VotingClassifier ausgleichen\n",
    "# Tendenziell die letzten beiden am besten, aber nur bis knapp über 50%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['LinearSVC -> 0.456303', 'LinearSVC -> 0.454756', 'LinearSVC -> 0.255220', 'LinearSVC -> 0.296210']\n"
     ]
    }
   ],
   "source": [
    "#for i in range(20):\n",
    "result = []\n",
    "for i, clf in enumerate(classifiersOpt):\n",
    "\n",
    "    c = clf.fit(X_train, y_train)\n",
    "    score = clf.score(X_test, y_test)\n",
    "\n",
    "    result.append('%s -> %f' % (type(c).__name__, score))\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVC und NuSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiersKernel = [\n",
    "    NuSVC(kernel='linear'),#51,5%\n",
    "    NuSVC(kernel='poly'),\n",
    "    NuSVC(kernel='rbf'),\n",
    "    NuSVC(kernel='sigmoid'),\n",
    "    #NuSVC(kernel='precomputed') not supported for sparse\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = []\n",
    "for i, clf in enumerate(classifiersKernel):\n",
    "    c = clf.fit(X_train, y_train)\n",
    "    score = clf.score(X_test, y_test)\n",
    "    \n",
    "    result.append('%s -> %f' % (type(c).__name__, score))\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DecisionTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = [\n",
    "    DecisionTreeClassifier()\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = []\n",
    "for i, clf in enumerate(classifiers):\n",
    "    c = clf.fit(X_train, y_train)\n",
    "    score = clf.score(X_test, y_test)\n",
    "    \n",
    "    result.append('%s -> %f' % (type(c).__name__, score))\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bagging Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiersBaseEstimator = [\n",
    "    BaggingClassifier(base_estimator=DecisionTreeClassifier()),\n",
    "    BaggingClassifier(base_estimator=LinearSVC()),\n",
    "    BaggingClassifier(base_estimator=DecisionTreeClassifier(max_depth=2)),\n",
    "    BaggingClassifier(base_estimator=SVC()),\n",
    "    BaggingClassifier(base_estimator=NuSVC()),\n",
    "    BaggingClassifier(base_estimator=LinearSVC(penalty='l2', dual=True, loss='squared_hinge', tol=10, multi_class='ovr', C=3.55, \n",
    "              fit_intercept=False, intercept_scaling=2, class_weight='balanced', max_iter=1)),\n",
    "    BaggingClassifier(base_estimator=LinearSVC(penalty='l2', dual=True, loss='squared_hinge', tol=100, multi_class='ovr', C=3.55,\n",
    "              fit_intercept=False, intercept_scaling=2, class_weight='balanced', max_iter=1)),\n",
    "]#letzte 3 über 50%\n",
    "\n",
    "classifiers = [\n",
    "    BaggingClassifier(base_estimator=DecisionTreeClassifier(), bootstrap=True,\n",
    "         bootstrap_features=False, max_features=1.0, max_samples=1.0,\n",
    "         n_estimators=10, n_jobs=1, oob_score=False, random_state=None,\n",
    "         verbose=0, warm_start=False),\n",
    "    BaggingClassifier(base_estimator=LinearSVC(), bootstrap=True,\n",
    "         bootstrap_features=False, max_features=1.0, max_samples=1.0,\n",
    "         n_estimators=10, n_jobs=1, oob_score=False, random_state=None,\n",
    "         verbose=0, warm_start=False),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = []\n",
    "for i, clf in enumerate(classifiersBaseEstimator):\n",
    "    c = clf.fit(X_train, y_train)\n",
    "    score = clf.score(X_test, y_test)\n",
    "    \n",
    "    result.append('%s -> %f' % (type(c).__name__, score))\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AdaBoost Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forrest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiersNEstimators = [\n",
    "    RandomForestClassifier(n_estimators=10000),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = []\n",
    "for i, clf in enumerate(classifiersNEstimators):\n",
    "    c = clf.fit(X_train, y_train)\n",
    "    score = clf.score(X_test, y_test)\n",
    "    \n",
    "    result.append('%s -> %f' % (type(c).__name__, score))\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gradient Boosting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = [\n",
    "    GradientBoostingClassifier()\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = []\n",
    "for i, clf in enumerate(classifiers):\n",
    "    c = clf.fit(X_train, y_train)\n",
    "    score = clf.score(X_test, y_test)\n",
    "    \n",
    "    result.append('%s -> %f' % (type(c).__name__, score))\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voting Classifier (soft, weighted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf1 = NuSVC(kernel='linear')\n",
    "clf2 = AdaBoostClassifier(algorithm='SAMME',base_estimator=NuSVC(kernel='linear'))\n",
    "clf3 = RandomForestClassifier(n_estimators=10000)#only trees\n",
    "clf4 = BaggingClassifier(base_estimator=NuSVC(kernel='linear'))\n",
    "clf5 = GradientBoostingClassifier()#only trees\n",
    "#clf6 = RandomTreesEmbedding()\n",
    "\n",
    "classifiers = [\n",
    "    clf1, clf2, clf3, clf4, clf5, #clf6,\n",
    "    VotingClassifier(estimators=[('abc', clf2), ('rfc', clf3), ('bc', clf4), ('gbc', clf5)], voting='soft'),\n",
    "    VotingClassifier(estimators=[('abc', clf2), ('rfc', clf3), ('gbc', clf5)], voting='soft')\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = []\n",
    "for i, clf in enumerate(classifiers):\n",
    "    c = clf.fit(X_train, y_train)\n",
    "    score = clf.score(X_test, y_test)\n",
    "    print(type(c).__name__)\n",
    "    print ('next')\n",
    "    result.append('%s -> %f' % (type(c).__name__, score))\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clustering -> voting with classification (geht so nicht...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = []\n",
    "eclf3 = VotingClassifier(estimators=[('ab', AdaBoostClassifier()), ('rf', RandomForestClassifier()), ('gb', GradientBoostingClassifier())], voting='soft')\n",
    "for i, clf in enumerate([eclf3, KMeans(n_clusters=3)]):\n",
    "    c = clf.fit(X_train, y_train)\n",
    "    score = clf.score(X_test, y_test)\n",
    "    \n",
    "    right=0\n",
    "    l=0\n",
    "    for i, p in enumerate(clf.predict(X_test)):\n",
    "        if (p == y_test[i]):\n",
    "            right += 1\n",
    "        l+=1\n",
    "    \n",
    "    print(right / len(y_test))\n",
    "    \n",
    "    result.append('%s -> %f' % (type(c).__name__, score))\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "timestamp mit nutzen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#featureTimestamp = fifa.drop([21515], axis=1).values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "clustern der teams und daraus classifizieren?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}